hyperparameters:
  learning_rate: 0.0003
  n_steps: 128
  batch_size: 1280
  n_epochs: 3
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  clip_range_vf: null
  normalize_advantage: True
  ent_coef: 0.0001
  vf_coef: 0.5
  max_grad_norm: 0.5
  use_sde: False
  sde_sample_freq: -1
  target_kl: null
  stats_window_size: 1
  device: "auto"
  verbose: 0
  policy_kwargs:
    net_arch:
      - 256
      - 256
max_steps: 100000000000000000
retraining_steps: 200_000

# Batch size troppo grande, miglioramenti avvengono troppo lentamente, addestramento va in early fail