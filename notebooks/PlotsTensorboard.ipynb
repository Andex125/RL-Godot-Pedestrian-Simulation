{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis and Visualization of Training Phase\n",
    "\n",
    "This notebook focuses on plotting and analyzing the training phase, including mean reward of each level and the total length of the phase, using the `tensorboard` logs. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importing Necessary Libraries\n",
    "\n",
    "The code in this cell imports the necessary libraries for data handling and visualization:\n",
    "\n",
    "1. **`os`**: This module provides a way of using operating system dependent functionality like reading or writing to the file system.\n",
    "   \n",
    "2. **`matplotlib.pyplot` as `plt`**: This module is used for creating static, animated, and interactive visualizations in Python. It provides a MATLAB-like interface for plotting.\n",
    "   \n",
    "3. **`pandas as pd`**: This library is used for data manipulation and analysis. It provides data structures and functions needed to manipulate structured data seamlessly.\n",
    "   \n",
    "4. **`matplotlib.lines as m_lines`**: This module within `matplotlib` is used for creating and manipulating line objects in a plot, which are essential for creating detailed and customized visualizations.\n",
    "\n",
    "These imports set up the necessary tools for reading data, manipulating it, and visualizing it effectively."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.lines as m_lines"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Normalization Function\n",
    "\n",
    "The `normalize_column` function is used to normalize the values in a specified column of a DataFrame to a range between 0 and 1. \n",
    "\n",
    "**Function Definition**:\n",
    "- **Input**: \n",
    "  - `df`: The DataFrame containing the data.\n",
    "  - `column_name`: The name of the column to be normalized.\n",
    "- **Output**: \n",
    "  - A Series with the normalized values of the specified column."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(df, column_name):\n",
    "    column = df[column_name]\n",
    "    normalized_column = (column - column.min()) / (column.max() - column.min())\n",
    "    return normalized_column"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract Last Six Digits Function\n",
    "\n",
    "The `extract_last_six_digits` function extracts the last six digits from a given number.\n",
    "\n",
    "**Function Definition**:\n",
    "- **Input**: \n",
    "  - `num`: The number from which to extract the last six digits.\n",
    "- **Output**: \n",
    "  - A string containing the last six digits of the input number."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_last_six_digits(num):\n",
    "    return str(num)[-6:]"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot Cumulative Reward Function\n",
    "\n",
    "The `plot_cumulative_reward` function is used to visualize the cumulative reward over time during the training phase of a model. This function takes a DataFrame containing the reward data, a DataFrame with step data, and a run name for the title.\n",
    "\n",
    "**Function Definition**:\n",
    "- **Input**:\n",
    "  - `df`: DataFrame containing reward data.\n",
    "  - `df_step`: DataFrame containing step information, including environment labels and minimum scores.\n",
    "  - `run_name`: A string representing the name of the run, used in the plot title.\n",
    "- **Output**:\n",
    "  - A plot displaying the cumulative reward and its smoothed version over time, along with environment phases and minimum scores.\n",
    "\n",
    "**Plot Components**:\n",
    "1. **Colors**:\n",
    "   - A predefined list of colors is used for differentiating environment phases.\n",
    "\n",
    "2. **Normalization and Smoothing**:\n",
    "   - The first column of `df` is normalized by subtracting the initial wall value.\n",
    "   - The cumulative reward data is smoothed using a rolling mean with a window of 10.\n",
    "\n",
    "3. **Figure and Axes**:\n",
    "   - A large figure is created for detailed visualization.\n",
    "   - Both the raw and smoothed cumulative reward are plotted.\n",
    "\n",
    "4. **Environment Phases**:\n",
    "   - Environment phases are indicated using vertical spans with varying opacity.\n",
    "   - Minimum scores are plotted as dashed horizontal lines.\n",
    "   - Phase labels are added vertically at appropriate positions.\n",
    "\n",
    "5. **Plot Customization**:\n",
    "   - Titles and labels are set for clarity.\n",
    "   - A legend is created to explain the plot elements."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_reward(df, df_step, run_name):\n",
    "    colors = [\n",
    "        '#264653', '#2a9d8f', '#e9c46a', '#f4a261', '#e76f51',\n",
    "        '#1d3557', '#457b9d', '#a8dadc', '#f77f00', '#d62828',\n",
    "        '#003049', '#d62828', '#f77f00', '#fcbf49', '#eae2b7',\n",
    "        '#2b2d42', '#8d99ae', '#edf2f4', '#ef233c', '#d90429',\n",
    "        '#ffadad', '#ffd6a5', '#fdffb6', '#caffbf', '#9bf6ff',\n",
    "        '#a0c4ff', '#bdb2ff', '#ffc6ff', '#fffffc', '#3a86ff',\n",
    "        '#8338ec', '#ff006e', '#fb5607', '#ffbe0b', '#00b4d8',\n",
    "        '#0077b6', '#90e0ef', '#caf0f8', '#ade8f4', '#48cae4'\n",
    "    ]\n",
    "\n",
    "    y_lim = -40\n",
    "    labels = df_step['Environment']\n",
    "    wall = df_step['Wall']\n",
    "    df_min_score = df_step['MinScore']\n",
    "\n",
    "    df['Normalized_Column'] = df.iloc[:, 0] - wall.iloc[0]\n",
    "    wall = wall - wall.iloc[0]\n",
    "    \n",
    "    df_smooth = df.iloc[:, 2].rolling(window=10).mean()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(22, 9))\n",
    "   \n",
    "    ax.plot(df['Normalized_Column'], df.iloc[:, 2], color=\"#3399e6\", lw=2, alpha=0.5, label=\"Cumulative Reward\")\n",
    "    ax.plot(df['Normalized_Column'], df_smooth, color=\"red\", lw=2, label=\"Cumulative Reward Smoothed\")\n",
    "\n",
    "    for i, val in enumerate(wall):\n",
    "        if i == 0 or (i != 0 and labels[i] != \"End\"):\n",
    "            ax.axvspan(wall[i] - 0.2, wall[i], facecolor=colors[i], alpha=0.8)\n",
    "            ax.axvspan(wall[i], wall[i + 1], facecolor=colors[i], alpha=0.4)\n",
    "            ax.hlines(y=float(df_min_score[i]), linestyle='--', color='black', lw=1,\n",
    "                      xmin=wall[i], xmax=wall[i + 1], label=f\"min score: {labels[i]}\")\n",
    "            ax.text((wall[i] + wall[i + 1]) / 2, y_lim + 2, labels[i], fontsize=16, color='black', rotation=\"vertical\")\n",
    "\n",
    "    ax.set_ylim(y_lim, 20)\n",
    "    # plt.title('Plot of cumulative reward during the model training phase: ' + run_name, fontsize=28)\n",
    "    plt.xlabel('Seconds', fontsize=20)\n",
    "    plt.ylabel('Mean Reward', fontsize=20)\n",
    "\n",
    "    red_line = m_lines.Line2D([], [], color='red', markersize=15, label='Cumulative Reward Smoothed', linewidth=2)\n",
    "    blue_line = m_lines.Line2D([], [], color='#3399e6', markersize=15, label='Cumulative Reward', linewidth=2)\n",
    "    black_dash_line = m_lines.Line2D([], [], color='black', markersize=15, label='Min Score', linewidth=2, linestyle='--')\n",
    "\n",
    "    plt.legend(handles=[blue_line, red_line, black_dash_line], loc='upper right', fontsize=20)\n",
    "    plt.savefig(f'../output/runs/{group}/{name}/plots/episode_reward_mean_{name}.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot Episode Length Function\n",
    "\n",
    "The `plot_episode_length` function is designed to visualize the length of episodes during a model's training phase. This plot can help identify trends in how long episodes last as the model trains and how they are influenced by different environments or phases of the training process.\n",
    "\n",
    "**Function Definition**:\n",
    "- **Inputs**:\n",
    "  - `df`: A DataFrame containing data on episode lengths.\n",
    "  - `df_step`: A DataFrame with metadata about the training steps, such as environments and their respective timestamps (walls).\n",
    "  - `run_name`: A string indicating the name of the training run, used in the plot title.\n",
    "- **Output**:\n",
    "  - A plot that illustrates the episode lengths across the training duration, highlighting different training environments.\n",
    "\n",
    "**Plot Components**:\n",
    "1. **Color Scheme**:\n",
    "   - A list of predefined colors used to visually distinguish between different training environments.\n",
    "\n",
    "2. **Data Normalization**:\n",
    "   - The first column of `df` is normalized relative to the initial timestamp in `wall`.\n",
    "\n",
    "3. **Smoothing**:\n",
    "   - Episode length data is smoothed using a rolling mean with a window size of 10 to better visualize trends.\n",
    "\n",
    "4. **Figure and Axes**:\n",
    "   - The plot is created on a large figure to accommodate detailed data visualization.\n",
    "\n",
    "5. **Environment Visualization**:\n",
    "   - Colored spans indicate different training environments.\n",
    "   - Environment labels are placed centrally within their respective spans for easy identification.\n",
    "\n",
    "6. **Final Touches**:\n",
    "   - A timestamp at the end of the last environment shows the total training time.\n",
    "   - Titles, labels, and a legend enhance the plot's readability."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_episode_length(df, df_step, run_name):\n",
    "    colors = [\n",
    "        '#264653', '#2a9d8f', '#e9c46a', '#f4a261', '#e76f51',\n",
    "        '#1d3557', '#457b9d', '#a8dadc', '#f77f00', '#d62828',\n",
    "        '#003049', '#d62828', '#f77f00', '#fcbf49', '#eae2b7',\n",
    "        '#2b2d42', '#8d99ae', '#edf2f4', '#ef233c', '#d90429',\n",
    "        '#ffadad', '#ffd6a5', '#fdffb6', '#caffbf', '#9bf6ff',\n",
    "        '#a0c4ff', '#bdb2ff', '#ffc6ff', '#fffffc', '#3a86ff',\n",
    "        '#8338ec', '#ff006e', '#fb5607', '#ffbe0b', '#00b4d8',\n",
    "        '#0077b6', '#90e0ef', '#caf0f8', '#ade8f4', '#48cae4'\n",
    "    ]\n",
    "\n",
    "    labels = df_step['Environment']\n",
    "    wall = df_step['Wall']\n",
    "    df_min_score = df_step['MinScore']\n",
    "\n",
    "    df['Normalized_Column'] = df.iloc[:, 0] - wall.iloc[0]\n",
    "    wall = wall - wall.iloc[0]\n",
    "    \n",
    "    df_smooth = df.iloc[:, 2].rolling(window=10).mean()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(22, 9))\n",
    "   \n",
    "    ax.plot(df['Normalized_Column'], df.iloc[:, 2], color=\"#3399e6\", lw=2, alpha=0.5, label=\"Episode Length\")\n",
    "    ax.plot(df['Normalized_Column'], df_smooth, color=\"red\", lw=2, label=\"Episode Length Smoothed\")\n",
    "\n",
    "    for i, val in enumerate(wall):\n",
    "        if i == 0 or (i != 0 and labels[i] != \"End\"):\n",
    "            ax.axvspan(wall[i] - 0.2, wall[i], facecolor=colors[i], alpha=0.8)\n",
    "            ax.axvspan(wall[i], wall[i + 1], facecolor=colors[i], alpha=0.4)\n",
    "            ax.text((wall[i] + wall[i + 1]) / 2, df.iloc[:, 2].min(), labels[i], fontsize=16, color='black', rotation=\"vertical\")\n",
    "\n",
    "    ax.text(wall.iloc[-1], df.iloc[:, 2].min(), str(round(wall.iloc[-1] / 60, 2)) + \" min\", fontsize=13, color='black')\n",
    "    \n",
    "    # plt.title('Plot of the episode length during the model training phase: ' + run_name, fontsize=28)\n",
    "    plt.xlabel('Second', fontsize=20)\n",
    "    plt.ylabel('Episode length', fontsize=20)\n",
    "    plt.legend(loc='upper right', fontsize=20)\n",
    "    plt.savefig(f'../output/runs/{group}/{name}/plots/episode_length_{name}.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup and Data Loading for Visualization of Training Performance Metrics\n",
    "\n",
    "The code provided below sets up file paths based on a specific model run, reads in necessary data, and processes timestamps for visualization purposes. It focuses on preparing data for two key aspects of model training: cumulative rewards and episode lengths.\n",
    "\n",
    "**Details**:\n",
    "\n",
    "1. **Variable Initialization**:\n",
    "   - `name`: Indicates the name of the run, used for file path construction.\n",
    "   - `group`: Indicates the folder in which the `name` run is contained. If the `name` run is directly inside the `runs` folder, `group` must be set to empty string. \n",
    "\n",
    "2. **File Paths**:\n",
    "   - `path_wall`: Path to the file that records changes in the environment.\n",
    "   - `path_env_cumulative_reward`: Path to the file containing data on cumulative rewards.\n",
    "   - `path_env_episode_length`: Path to the file containing data on episode lengths.\n",
    "\n",
    "3. **Data Reading and Preprocessing**:\n",
    "   - `df_wall`: Reads the environment changes data, removes unnecessary columns, and processes the 'Wall' column to extract significant digits for timestamps.\n",
    "   - `df_env_cumulative_reward`: Reads the cumulative reward data, converts timestamps, and extracts significant digits for easier processing and visualization."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "name = \"net_256_128_64\"\n",
    "group = 'sensitivity_studies'\n",
    "\n",
    "path_wall = f\"../output/runs/{group}/{name}/EnvironmentChanges.txt\"\n",
    "df_wall = pd.read_csv(path_wall, decimal=\",\", delimiter=\";\", names=[\"Time\", \"Wall\", \"Second\", \"Environment\", \"MinScore\", \"Phase\"])\n",
    "df_wall = df_wall.drop(columns=['Time', 'Second'])\n",
    "df_wall['Wall'] = df_wall['Wall'].astype(int).apply(extract_last_six_digits).astype(int)\n",
    "\n",
    "path_env_cumulative_reward = f\"../output/runs/{group}/{name}/tensorboard_export/run-PPO_1-tag-rollout_ep_rew_mean.csv\"\n",
    "path_env_episode_length = f\"../output/runs/{group}/{name}/tensorboard_export/run-PPO_1-tag-rollout_ep_len_mean.csv\"\n",
    "\n",
    "df_env_cumulative_reward = pd.read_csv(path_env_cumulative_reward, decimal=\".\", delimiter=\",\")\n",
    "df_env_cumulative_reward['Wall time'] = df_env_cumulative_reward['Wall time'].astype(int).apply(extract_last_six_digits).astype(int)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualization of Model Training Metrics\n",
    "\n",
    "The following code snippets execute the visualization functions for the cumulative rewards and episode lengths during a model training session. These visualizations provide insights into the model's performance across different environmental changes and training phases.\n",
    "\n",
    "**Function Calls**:\n",
    "\n",
    "1. **Cumulative Reward Visualization**:\n",
    "   - `plot_cumulative_reward(df_env_cumulative_reward, df_wall, name)`: This function plots the cumulative rewards over time, highlighting changes in the training environment and smoothing the rewards to identify trends more clearly.\n",
    "\n",
    "2. **Episode Length Visualization** (Conditional):\n",
    "   - First, it checks if the episode length data file exists using `os.path.exists(path_env_episode_length)`.\n",
    "   - If the file exists, it reads the data, processes timestamps, and then calls `plot_episode_length(df_env_episode_length, df_wall, name)` to visualize how the length of episodes varies over time and across different phases of the environment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_cumulative_reward(df_env_cumulative_reward, df_wall, name)\n",
    "\n",
    "if os.path.exists(path_env_episode_length):\n",
    "    df_env_episode_length = pd.read_csv(path_env_episode_length, decimal=\".\", delimiter=\",\")\n",
    "    df_env_episode_length['Wall time'] = df_env_episode_length['Wall time'].astype(int).apply(extract_last_six_digits).astype(int)\n",
    "    plot_episode_length(df_env_episode_length, df_wall, name)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51fa0a07f6fd5e060b837a66c96d41582ff23df34b38f2e72cb4e3ebfbe13406"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
